{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBERS DATA CUBE: A POWERFUL TECHNOLOGY FOR MAPPING AND MONITORING BRAZILIAN BIOMES (Replicability test)\n",
    "\n",
    "**Abstract**\n",
    "\n",
    "<div style=\"text-align: justify\">\n",
    "Currently, the overwhelming amount of Earth Observation data demands new solutions regarding processing and storage. To reduce the amount of time spent in searching, downloading and pre-processing data, the remote Sensing community is coming to an agreement on the minimum amount of corrections satellite images must convey in order to reach the broadest range of applications. Satellite imagery meeting such criteria (which usually include atmospheric, radiometric and topographic corrections) are generically called Analysis Ready Data (ARD). Furthermore, ARD is being assembled into multidimensional data cubes, minimising pre- processing tasks and allowing scientists and users in general to focus on analysis. A particular instance of this is the Brazil Data Cube (BDC) project, which is processing remote sensing images of medium spatial resolution into ARD datasets and assembling them as multidimensional cubes of the Brazilian territory. For example, BDC users are released from performing tasks such as image co-registration , aerosol interference correction. This work presents a BDC proof of concept, by analysing a BDC data cube made with images from the fourth China-Brazil Earth Resources Satellite (CBERS-4) of one of the largest biodiversity hotspot in the world, the Cerrado biome. It also shows how to map and monitor land use and land cover using the CBERS data cube. We demonstrate that the CBERS data cube is effective in resolving land use and and land cover issues to meet local and national needs related to the landscape dynamics, including deforestation, carbon emissions, and public policies.\n",
    "</div>    \n",
    "\n",
    "**DOI**: [10.5194/isprs-annals-V-3-2020-533-2020](10.5194/isprs-annals-V-3-2020-533-2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cerrado Biome classification using CBERS datacubes\n",
    "\n",
    "This document will present the steps used to generate the classification map presented in the paper. As presented in the article, the classification process was done using the [SITS R package](github.com/e-sensing/sits).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Seed to results reproducibility\n",
    "#\n",
    "set.seed(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Computational resources\n",
    "#\n",
    "memsize <- 2\n",
    "multicores <- 2\n",
    "\n",
    "#\n",
    "# classification definitions\n",
    "#\n",
    "num_trees <- 1000\n",
    "\n",
    "#\n",
    "# post-processing definition\n",
    "#\n",
    "smoothing <- \"bayesian\"\n",
    "\n",
    "#\n",
    "# shapefile\n",
    "#\n",
    "shp_filename <- \"\"\n",
    "shp_directory <- \"\"\n",
    "shp_class_attribute <- \"label\"\n",
    "\n",
    "#\n",
    "# bricks configurations\n",
    "#\n",
    "bands <- \"\"\n",
    "timeline <- \"\"\n",
    "\n",
    "bricks_dir <- \"\"\n",
    "bricks_names <- \"\"\n",
    "\n",
    "#\n",
    "# output\n",
    "#\n",
    "output_dir <- \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Processing input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# samples\n",
    "#\n",
    "input_samples_shapefile <- paste(shp_directory, shp_filename, sep = \"/\")\n",
    "\n",
    "#\n",
    "# extract bands\n",
    "#\n",
    "bands <- unlist(strsplit(bands, \",\"))\n",
    "\n",
    "#\n",
    "# extract timeline\n",
    "#\n",
    "timeline <- unlist(strsplit(timeline, \",\"))\n",
    "\n",
    "#\n",
    "# extract brick names\n",
    "#\n",
    "bricks_names <- unlist(strsplit(bricks_names, \",\"))\n",
    "bricks <- unlist(lapply(X = bricks_names, FUN = function(x) {\n",
    "    paste(bricks_dir, x, sep = \"/\")\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**output directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir.create(paste(output_dir, \"out\", sep = \"/\"), recursive = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(sits)\n",
    "library(rgdal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generating datacube using RasterBricks**\n",
    "\n",
    "The classification process was done with the use of RasterBricks. In general, RasterBricks represent rasters files with multiple dimensions, where each dimension represents an instant of time of a given place and spectral band. Thus, ten RasterBricks are used, one for each spectral band. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brick_cube <- sits_cube(\n",
    "                   type      = \"BRICK\",\n",
    "                   name      = \"Picoli-etal_CUBE\",\n",
    "                   satellite = \"CBERS-4\",\n",
    "                   sensor    = \"AWFI\",\n",
    "                   timeline  = timeline,\n",
    "                   bands     = bands,\n",
    "                   files     = bricks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification**\n",
    "\n",
    "Now the classification can be done, as presented in the article, will be made using the Random Forest algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load samples to train Random Forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# extract time-series\n",
    "#\n",
    "samples <- sits_get_data(brick_cube, file = input_samples_shapefile, shp_attr = shp_class_attribute)\n",
    "\n",
    "#\n",
    "# show extracted time-series\n",
    "#\n",
    "head(samples$time_series[[1]], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Fold training**\n",
    "\n",
    "Before performing the classification of an entire data cube (which can take a while), to then check the results, below is done the K-Fold Cross-Validation. In this, the model is trained with different configurations of the data set, and the general accuracy is the average of the accuracy obtained in the different settings.\n",
    "\n",
    "> The configuration used below works with five folds (K in `K`-Folds), indicating that 80% of the data was chosen for training and 20% for testing for each training.\n",
    "\n",
    "> This process is being done to compare the new cube results with the old ones used to create the original article.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sits_kfold_validate(samples, \n",
    "                     folds     = 5,\n",
    "                     ml_method = sits_rfor(num_trees = num_trees)) %>%\n",
    "                     sits_conf_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train an Random Forest Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfor_model <- sits_train(data      = samples,\n",
    "                         ml_method = sits_rfor(num_trees = num_trees))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classify the datacube**\n",
    "\n",
    "> This is a time-consuming process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs <- sits_classify(data       = brick_cube,\n",
    "                       ml_model   = rfor_model,\n",
    "                       memsize    = memsize,\n",
    "                       multicores = multicores,\n",
    "                       output_dir = output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate classification label map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# smoothing using 5x5 (sits default in v.0.10.0)\n",
    "#\n",
    "probs_smoothed <- sits_smooth(probs, \n",
    "                              type       = smoothing, \n",
    "                              output_dir = output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# generate labels\n",
    "#\n",
    "labels <- sits_label_classification(cube       = probs,\n",
    "                                    output_dir = output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveRDS(probs, file = paste0(output_dir, \"probs_cube.rds\"))\n",
    "save(probs,    file = paste0(output_dir, \"probs_cube.Rdata\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveRDS(labels, file = paste0(output_dir, \"labels_cube.rds\"))\n",
    "save(labels,    file = paste0(output_dir, \"labels_cube.Rdata\"))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
